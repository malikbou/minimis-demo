import { AIModel } from "@/types/models";

export const aiModels: AIModel[] = [
  {
    slug: "whisper-cpp",
    modelName: "whisper.cpp",
    repoLink: "https://github.com/ggerganov/whisper.cpp",
    tagline: "Lightweight Speech-to-Text",
    description: "A C/C++ implementation of OpenAI's Whisper model for efficient speech recognition in low-resource environments.",
    type: "Audio",
    difficulty: "Easy",
    useCases: "Transcribing lectures, real-time note taking, accessibility",
    hardwareRequirements: "✅ 4GB RAM | Windows/macOS/Linux",
    instructions: "1. Download the executable. 2. Run from your terminal. 3. Provide an audio file or use your mic.",
    exampleUsage: "Try: 'What's the weather like today?'",
    downloadLink: "https://example.com/whisper-cpp-download",
    demoMediaUrl: "https://example.com/whisper-cpp-demo.gif",
    ethicalUse: "Ensure privacy when transcribing personal conversations.",
    additionalResources: "Documentation, GitHub issues, community forum"
  },
  {
    slug: "stable-diffusion-cpp",
    modelName: "stable diffusion.cpp",
    repoLink: "https://github.com/leejet/stable-diffusion.cpp",
    tagline: "AI Image Generation Made Simple",
    description: "A pure C/C++ implementation of Stable Diffusion that generates high-quality images from text prompts.",
    type: "Image",
    difficulty: "Medium",
    useCases: "Art, creative storytelling, classroom projects",
    hardwareRequirements: "✅ 4GB RAM | Windows/macOS/Linux",
    instructions: "1. Download the model. 2. Run the executable. 3. Input a creative prompt to generate images.",
    exampleUsage: "Try: 'A futuristic city at night'",
    downloadLink: "https://example.com/stable-diffusion-cpp-download",
    demoMediaUrl: "https://example.com/stable-diffusion-demo.gif",
    ethicalUse: "Avoid generating harmful or explicit content.",
    additionalResources: "Installation guide, prompt tips, community discussions"
  },
  {
    slug: "llama-cpp",
    modelName: "llama.cpp",
    repoLink: "https://github.com/ggerganov/llama.cpp",
    tagline: "Efficient Language Model Inference",
    description: "An optimized C/C++ implementation of Meta's LLaMA for local text generation and natural language processing.",
    type: "Text",
    difficulty: "Medium",
    useCases: "Essay writing, creative storytelling, code generation",
    hardwareRequirements: "✅ 8GB RAM recommended | Windows/macOS/Linux",
    instructions: "1. Download and compile the code. 2. Run with a text prompt. 3. Interact with the output.",
    exampleUsage: "Try: 'Write a short story about a dragon and a princess'",
    downloadLink: "https://example.com/llama-cpp-download",
    demoMediaUrl: "https://example.com/llama-cpp-demo.gif",
    ethicalUse: "Monitor for biases and use for educational purposes.",
    additionalResources: "User guide, prompt engineering tips, community forum"
  },
  {
    slug: "intel-openvino",
    modelName: "Intel OpenVINO",
    repoLink: "https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html",
    tagline: "Accelerate AI with Intel",
    description: "A toolkit to optimize and deploy AI inference on Intel hardware, boosting performance for various models.",
    type: "Various",
    difficulty: "Hard",
    useCases: "Object detection, image classification, industrial applications",
    hardwareRequirements: "Intel CPU; Windows/macOS/Linux compatible",
    instructions: "1. Download the OpenVINO toolkit. 2. Configure your environment. 3. Run optimized models.",
    exampleUsage: "Try: 'Run an object detection model on a sample image'",
    downloadLink: "https://example.com/intel-openvino-download",
    demoMediaUrl: "https://example.com/intel-openvino-demo.gif",
    ethicalUse: "Follow Intel's deployment and privacy guidelines.",
    additionalResources: "Developer documentation, tutorials, community forums"
  },
  {
    slug: "deepseek",
    modelName: "DeepSeek",
    repoLink: "https://github.com/deepseek/deepseek",
    tagline: "Advanced Information Retrieval",
    description: "An AI-powered search and document analysis model designed for deep semantic understanding and data mining.",
    type: "Text/Document",
    difficulty: "Medium",
    useCases: "Research, data mining, content recommendation",
    hardwareRequirements: "✅ 8GB RAM | Windows/macOS/Linux",
    instructions: "1. Download DeepSeek. 2. Run the executable with your query. 3. Review the semantic search results.",
    exampleUsage: "Try: 'Find research papers on AI ethics'",
    downloadLink: "https://example.com/deepseek-download",
    demoMediaUrl: "https://example.com/deepseek-demo.gif",
    ethicalUse: "Use ethically for unbiased and transparent search results.",
    additionalResources: "Documentation, community support, research articles"
  },
  {
    slug: "onnx",
    modelName: "ONNX Runtime",
    repoLink: "https://github.com/microsoft/onnxruntime",
    tagline: "Interoperable AI Execution",
    description: "ONNX Runtime delivers high performance for running AI models across frameworks, ensuring compatibility and speedy inference.",
    type: "Various",
    difficulty: "Medium",
    useCases: "Cross-platform deployment, model interoperability",
    hardwareRequirements: "✅ 4GB RAM | Windows/macOS/Linux; GPU optional",
    instructions: "1. Download ONNX Runtime. 2. Integrate with your AI model. 3. Run inference on your data.",
    exampleUsage: "Try: 'Run an image classification model using ONNX'",
    downloadLink: "https://example.com/onnx-download",
    demoMediaUrl: "https://example.com/onnx-demo.gif",
    ethicalUse: "Ensure fairness and follow cross-framework guidelines.",
    additionalResources: "ONNX documentation, integration tutorials, community forums"
  }
];
